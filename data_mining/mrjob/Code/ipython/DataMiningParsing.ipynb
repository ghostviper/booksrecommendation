{
 "metadata": {
  "name": "DataMining3"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "from collections import defaultdict\n",
      "import sqlite3 as lite\n",
      "import sys\n",
      "from collections import defaultdict\n",
      "\n",
      "# relative to parent dir\n",
      "DATA_FILES = {#\"books\":\"/Users/sonali/Documents/Ischool/INFODMA/Project/BX-Book-Ratings.csv\",\n",
      "              \"books\":\"/Users/sonali/Documents/Ischool/INFODMA/Project/testBXUsers.csv\",\n",
      "               \"ratings\":\"/Users/sonali/Documents/Ischool/INFODMA/DataSets/test/\",\n",
      "                \"users\":\"/Users/sonali/Documents/Ischool/INFODMA/Project/BX-Users.csv\"}\n",
      "\n",
      "def file_path(key):\n",
      "    return os.path.join(os.pardir, DATA_FILES[key])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# add all lines to the sqlite atabase\n",
      "import sqlite3\n",
      "import pandas as pd\n",
      "from pandas import DataFrame\n",
      "from pandas.io import sql\n",
      "import StringIO\n",
      "from itertools import islice \n",
      "\n",
      "def df_from_booksrating(max_line,page_size):\n",
      "   # hathi_file_path = os.path.join(os.pardir, \"/Users/sonali/Documents/Ischool/Opendata/Project/hathi_full_20130301.txt\")\n",
      "    x = open(file_path(\"books\"))\n",
      "    f = StringIO.StringIO(\"\".join(list(islice(x, max_line))))\n",
      "    tp = pd.read_csv(f, iterator=True, chunksize=1000, header=None,names=['User-ID','ISBN','Book-Rating'], delimiter=\";\")\n",
      "    #tp = pd.read_csv(f, iterator=True, chunksize=1000, header=None,names=['UserID','Location','Age'], delimiter=\";\")\n",
      "    for chunk in tp:\n",
      "        df = pd.DataFrame(chunk)\n",
      "        print df\n",
      "        sql.write_frame(pd.DataFrame(chunk), name='BXBookRatings', con=cnx, if_exists='append')\n",
      "        #sql.write_frame(pd.DataFrame(chunk), name='testBXUser', con=cnx, if_exists='append')\n",
      "        cnx.commit()\n",
      "    #return pd.concat([chunk for chunk in tp], ignore_index=True)\n",
      "max_line = 120000\n",
      "page_size = 1000\n",
      "\n",
      "cnx = sqlite3.connect('Books.db')\n",
      "cnx.text_factory = str\n",
      "df_from_booksrating(max_line,page_size)\n",
      "#sql.write_frame(df, name='Hathitrust', con=cnx, if_exists='append')\n",
      "cnx.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# add all lines to the sqlite by changing the location , THIS IS NOT WORKING\n",
      "import sqlite3\n",
      "import pandas as pd\n",
      "from pandas import DataFrame\n",
      "from pandas.io import sql\n",
      "import StringIO\n",
      "from itertools import islice \n",
      "\n",
      "def df_from_booksrating(max_line,page_size):\n",
      "   # hathi_file_path = os.path.join(os.pardir, \"/Users/sonali/Documents/Ischool/Opendata/Project/hathi_full_20130301.txt\")\n",
      "    x = open(file_path(\"users\"))\n",
      "    f = StringIO.StringIO(\"\".join(list(islice(x, max_line))))\n",
      "    #tp = pd.read_csv(f, iterator=True, chunksize=1000, header=None,names=['User-ID','ISBN','Book-Rating'], delimiter=\";\")\n",
      "    tp = pd.read_csv(f, iterator=True, chunksize=1000, header=False,names=['UserID','Location','Age'], delimiter=\";\")\n",
      "    for chunk in tp:\n",
      "        #print \"RUNNING\"\n",
      "        tmplocation = map(lambda x:x.split(\",\")[2],chunk.Location)\n",
      "        print tmplocation\n",
      "        chunk.Location = tmplocation\n",
      "        df = pd.DataFrame(chunk)\n",
      "        #print df\n",
      "        #sql.write_frame(pd.DataFrame(chunk), name='BXBookRatings', con=cnx, if_exists='append')\n",
      "        sql.write_frame(pd.DataFrame(chunk), name='tmpBXUser1', con=cnx, if_exists='append')\n",
      "        cnx.commit()\n",
      "    #return pd.concat([chunk for chunk in tp], ignore_index=True)\n",
      "\n",
      "max_line = 2900000\n",
      "page_size = 50\n",
      "\n",
      "cnx = sqlite3.connect('Books.db')\n",
      "cnx.text_factory = str\n",
      "df_from_booksrating(max_line,page_size)\n",
      "#sql.write_frame(df, name='Hathitrust', con=cnx, if_exists='append')\n",
      "cnx.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#incomplete and not working\n",
      "import re\n",
      "fileopen = open(file_path(\"books\"))\n",
      "newfile = open(\"newBXUsers1.csv\",\"w\")\n",
      "for row in islice(fileopen,1,None):\n",
      "    #print row\n",
      "    tmp=row.split(\";\")\n",
      "    #print tmp\n",
      "    try:\n",
      "        print tmp[1]\n",
      "        p = re.compile(',[/w/d/s\\\"]$')\n",
      "        m = p.search(tmp[1]).group(1)\n",
      "        print m\n",
      "        #location = tmp[1].split(\",\")[2]\n",
      "        #newloc= location\n",
      "    except AttributeError as a:\n",
      "        print a\n",
      "        print \"exception\"\n",
      "        #print tmp[1]\n",
      "        #newloc=\"None\"\n",
      "    try:\n",
      "        age = tmp[2]\n",
      "    except:\n",
      "        \n",
      "        age=\"None\"\n",
      "    #print newloc\n",
      "        print tmp[0]+\";\\\"\"+newloc.strip()+\";\"+age\n",
      "    #newfile.write(tmp[0]+\";\\\"\"+newloc.strip()+\";\"+age+\"\\n\")\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "IndexError",
       "evalue": "no such group",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-170-f1ee67c918f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m',[/w/d/s\\\"]$'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m#location = tmp[1].split(\",\")[2]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mIndexError\u001b[0m: no such group"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\"west vancouver, british columbia, canada\"\n",
        "'NoneType' object has no attribute 'group'\n",
        "exception\n",
        "\"bloomington, indiana, usa\"\n",
        "'NoneType' object has no attribute 'group'\n",
        "exception\n",
        "\"deer park, texas, usa\"\n",
        "'NoneType' object has no attribute 'group'\n",
        "exception\n",
        "\"leicester, england, united kingdom\"\n",
        "'NoneType' object has no attribute 'group'\n",
        "exception\n",
        "\"crowborough, england,\"\n"
       ]
      }
     ],
     "prompt_number": 170
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#gathering null statistics and average values:\n",
      "cnx = sqlite3.connect('Books.db')\n",
      "cur = con.cursor()\n",
      "cnx.text_factory = str\n",
      "cur.execute(\"SELECT UserID,Location, count(1) FROM BXUsers where age IS NULL GROUP BY Location\")\n",
      "rows=cur.fetchall()\n",
      "print rows"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#create separate files based on age group and location (usa vs non usa)\n",
      "#performed on sqlite console\n",
      ".mode csv\n",
      ".output  .output '/Data/BXBookRatingsUsa25.txt'\n",
      "select * from `BXBookRatings` join \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "con = lite.connect('Books.db')\n",
      "with con:    \n",
      "    cur = con.cursor()    \n",
      "    cur.execute(\"SELECT COUNT(1) FROM BooksRating\")\n",
      "    rows=cur.fetchall()\n",
      "    print rows\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def booksSubSet(fromage,toage,location): \n",
      "    x= defaultdict(list)\n",
      "    con = lite.connect('Books.db')\n",
      "    bookslist= list()\n",
      "    ratings= defaultdict(list)\n",
      "    with con:    \n",
      "        cur = con.cursor()    \n",
      "        cur.execute(\"SELECT r.* FROM BooksRating r join 'BX-Users' u on u.'User-ID' = R.UserId where age>=\"+str(fromage)+\" and age<=\"+str(toage)+\" and Location like '%\"+location+\"' and rating>0 \")\n",
      "        #cur.execute(\"SELECT r.* FROM BooksRating r join 'BX-Users' u on u.'User-ID' = R.UserId where ISBN IN ('0312866275','0553099590')\")\n",
      "        rows = cur.fetchall()\n",
      "        for row in rows:\n",
      "            t= (row[2],row[3])\n",
      "            if row[1]==0:\n",
      "                pass\n",
      "            ratings[str(row[1])].append(t)\n",
      "            bookslist.append(row[2])\n",
      "    return (bookslist,ratings)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getaverageratings(d):\n",
      "    useravgrating=defaultdict(list)\n",
      "    for keys,values in d.iteritems():\n",
      "        counter=0.0\n",
      "        lenval = float(len(values))\n",
      "        for val in values:\n",
      "            counter=counter+ val[1]\n",
      "        avg=counter/lenval\n",
      "        tmpkey=str(keys)\n",
      "        useravgrating[tmpkey]=avg\n",
      "        avg=0.0\n",
      "        counter=0.0\n",
      "    return useravgrating"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#d"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#testing file writing\n",
      "def write_to_file_sim(key,sim):\n",
      "    with open(\"SimilarityMatrixnew\"+str(startindex)+\"_\"+str(endindex)+\".txt\", \"a\") as myfile:\n",
      "        myfile.write(str(key)+\"\\t\"+str(sim)+\"\\n\")\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def findpairs(books,d): \n",
      "    first = 0\n",
      "    second = 0 \n",
      "    userdict=defaultdict()\n",
      "    commonuser=defaultdict(list)\n",
      "    for userkey, values in d.iteritems():\n",
      "        #print \"--------------\"\n",
      "        #print userkey\n",
      "        #print values\n",
      "        #print type(values)\n",
      "        for s in values:\n",
      "            if s[0]==books[0]:\n",
      "                t1=s\n",
      "                first=1\n",
      "            if s[0]==books[1]:\n",
      "                t2=s\n",
      "                second=1\n",
      "        #print \"--------------\"\n",
      "        if (first==1 and second==1):\n",
      "            tmptuple=(t1[1],t2[1])\n",
      "            #userdict[userkey].append(tmptuple)\n",
      "            #print \"--------------\"\n",
      "            #print \"tuple\"\n",
      "            #print  (books[0],books[1])\n",
      "            #print \"/tuple\"\n",
      "            #print userkey\n",
      "            #print \"*******\"\n",
      "            #print t1\n",
      "            #print t2\n",
      "            #print \"*******\"\n",
      "            #print \"--------------\"\n",
      "            commonuser[books[0]+\"_\"+books[1]].append({userkey:tmptuple})\n",
      "            #commonuser.to_csv(\"testcommonusertest.txt\")\n",
      "            similarity(commonuser,avgratings)\n",
      "        first=0\n",
      "        second=0\n",
      "        t1=()\n",
      "        t2=()\n",
      "        tmptuple=()\n",
      "        #print commonuser\n",
      "        commonuser.clear()\n",
      "       \n",
      "   # return commonuser"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#entered similarity\n",
      "#defaultdict(<type 'list'>, {'82191': 7, '192705': 8, '132173': 7}) #useraveragerating\n",
      "#defaultdict(<type 'list'>, {u'0312866275_0553099590': [{'82191': (5, 9)}]}) #booksdict\n",
      "q = {u'0312866275_0553099590': [{'82191': (1, 9)},{'192705': (9, 1)},{'132173': (5, 5)}]}\n",
      "w = {'82191': 7, '192705': 8, '132173': 7}\n",
      "similarity(q,w)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def similarity(booksdict,useravgrating):  \n",
      "    #print \"entered similarity\"\n",
      "    #print useravgrating\n",
      "    #print \"common Users\"\n",
      "    #print booksdict\n",
      "    #print \"end common user\"\n",
      "    n=0\n",
      "    d1=list()\n",
      "    d2=list()\n",
      "    for key,value in booksdict.iteritems():\n",
      "        for val in value:\n",
      "            #print type(val)\n",
      "            for a,b in val.iteritems():\n",
      "                #print a\n",
      "                #print b\n",
      "                #print type(i)\n",
      "                #for k,v in i.iteritems():\n",
      "                 #   print k\n",
      "                #print useravgrating[a]\n",
      "                n=n+((b[0]-useravgrating[a])*(b[1]-useravgrating[a]))\n",
      "                d1.append(b[0]-useravgrating[a])\n",
      "                #print d1\n",
      "                d2.append(b[1]-useravgrating[a])\n",
      "                #print d2\n",
      "    #print n\n",
      "    d1 = map(lambda x:x**2,d1)   \n",
      "    #print d1\n",
      "    d2 = map(lambda x:x**2,d2)  \n",
      "    #print d2\n",
      "    tmpsum = ((sum(d1)**0.5)*(sum(d2)**0.5))\n",
      "    if tmpsum==0:\n",
      "        pass\n",
      "    else:\n",
      "        sim = float(n)/((sum(d1)**0.5)*(sum(d2)**0.5))\n",
      "        #print sim\n",
      "        write_to_file_sim(key,sim)\n",
      "           \n",
      "            \n",
      "            \n",
      "            \n",
      "            \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from itertools import combinations\n",
      "from itertools import islice\n",
      "#tmp = list(set(booksSubSet(70,70,\"usa\")))\n",
      "startindex = 16\n",
      "endindex = 16\n",
      "b,r = booksSubSet(startindex,endindex,\"usa\")\n",
      "avgratings = getaverageratings(r)\n",
      "#print b\n",
      "tmp = list(set(b))\n",
      "#print tmp\n",
      "#print r\n",
      "#tmp = [u'0312866275',u'0553099590']\n",
      "t = combinations(tmp,2)\n",
      "for y in islice(t,None):\n",
      "    #print y\n",
      "    findpairs(y,r) \n",
      "    #commonuser = similarity(y)\n",
      "    #commonuser "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "np.array\n",
      "y = [2,3,4]\n",
      "y = map(lambda x:(x-1)**2,y)\n",
      "y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "import math\n",
      "testing = defaultdict(list)\n",
      "testing['book1_book2'].append([{'1':(1,5)},{'2':(5,1)},{'3':(9,10)}])\n",
      "#useravgrating={'1':3,'2':3.5,'3':4}\n",
      "#testing['book1_book2'].append([(5,6),(2,4),(10,1),(9,8)])\n",
      "testing\n",
      "d1=list()\n",
      "d2=list()\n",
      "n=0\n",
      "for key,value in testing.iteritems():\n",
      "    for val in value:\n",
      "        for i in val:\n",
      "            for k,v in i.iteritems():\n",
      "                print k\n",
      "                print useravgrating[k]\n",
      "                n=n+((v[0]-useravgrating[k])*(v[1]-useravgrating[k]))\n",
      "                d1.append(v[0]-useravgrating[k])\n",
      "                print d1\n",
      "                d2.append(v[1]-useravgrating[k])\n",
      "                print d2\n",
      "print n\n",
      "d1 = map(lambda x:x**2,d1)   \n",
      "print d1\n",
      "d2 = map(lambda x:x**2,d2)  \n",
      "print d2\n",
      "sim = n/((sum(d1)**0.5)*(sum(d2)**0.5))\n",
      "print sim\n",
      "                \n",
      "          \n",
      "        \n",
      "        \n",
      "    "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "s = [(2,4),(5,2),(8,7)]\n",
      "for q in s:\n",
      "    if (q[0]==2):\n",
      "        print \"found1\"\n",
      "    if (q[1]==2):\n",
      "        print \"found2\"\n",
      "t=(2,3)\n",
      "t"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tmp = [u'0312866275',u'0553099590']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#out_list = [c for i in range(len(in_list)) for c in itertools.combinations(in_list, i+1)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "useravgrating['65095']\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a = {'user1':[('b1',5),('b2',5),('b3',5),('b4',5)],\n",
      "'user2':[('b4',7),('b5',2)],\n",
      "'user3':[('b2',3),('b1',2)],\n",
      "'user4':[('b1',1),('b7',9),('b2',10)],\n",
      "'user5':[('b4',5),('b3',6)]}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for keys,values in a.iteritems():\n",
      "    x=0\n",
      "    #print \"===============\"\n",
      "    #print keys\n",
      "    t = len(values)\n",
      "    #print \"===============\"\n",
      "    for i in values:\n",
      "        x=x+ i[1]\n",
      "        #print i[1]\n",
      "        #print x\n",
      "        #print \"===============\"\n",
      "        #c=c+1\n",
      "    avg=x/t\n",
      "    #print avg\n",
      "    y[keys]=avg\n",
      "    avg=0\n",
      "    x=0\n",
      "y      "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}